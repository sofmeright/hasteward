---
# cnpg-heal-replica.yml - Ansible playbook to heal unhealthy CNPG PostgreSQL replica
#
# This playbook heals a diverged/unhealthy replica by:
# 1. Fencing the instance (CNPG stops managing it)
# 2. Creating a heal pod, then aggressively deleting the fenced pod
# 3. Heal pod clears pgdata AND runs pg_basebackup from primary
# 4. Removing the fence (CNPG takes over the replica)
#
# Matches behavior of bash/maintenance/cnpg-heal-replica.sh:
# - Appends to existing fence list (preserves other fences)
# - Aggressive delete loop for PVC acquisition
# - block/rescue/always cleanup (heal pod + fence guidance on failure)
# - Separate UID/GID retrieval
# - Fail-fast on heal pod failure during PVC wait
#
# Usage:
#   docker run -it --rm \
#     -v ~/.kube:/root/.kube:ro \
#     -v /srv/dungeon/ansible:/app:ro \
#     prplanit/ansible-oci:2.20.1-v2 \
#     ansible-playbook k8s/recovery/cnpg-heal-replica.yml \
#       -e cluster_name=zitadel-postgres \
#       -e namespace=zeldas-lullaby \
#       -e replica_number=3
#
# Non-interactive:
#   ... -e auto_confirm=true

- name: Heal CNPG PostgreSQL Replica
  hosts: localhost
  connection: local
  gather_facts: true

  vars:
    heal_timeout: 600
    delete_timeout: 300
    auto_confirm: false

  tasks:
    # =========================================================================
    # Pre-flight validation
    # =========================================================================
    - name: Validate required variables
      ansible.builtin.assert:
        that:
          - cluster_name is defined
          - namespace is defined
          - replica_number is defined
        fail_msg: "Required variables: cluster_name, namespace, replica_number"

    - name: Set derived variables
      ansible.builtin.set_fact:
        target_pod: "{{ cluster_name }}-{{ replica_number }}"
        target_pvc: "{{ cluster_name }}-{{ replica_number }}"
        ca_secret: "{{ cluster_name }}-ca"
        replication_secret: "{{ cluster_name }}-replication"
        heal_pod: "{{ cluster_name }}-heal-{{ replica_number }}-{{ ansible_date_time.epoch }}"
        heal_fence_applied: false
        heal_pod_created: false

    - name: Display operation details
      ansible.builtin.debug:
        msg:
          - "=== CNPG Replica Healer ==="
          - "Cluster: {{ cluster_name }}"
          - "Namespace: {{ namespace }}"
          - "Target replica: {{ target_pod }}"

    # =========================================================================
    # Pre-flight checks
    # =========================================================================
    - name: Check if cluster exists
      kubernetes.core.k8s_info:
        api_version: postgresql.cnpg.io/v1
        kind: Cluster
        name: "{{ cluster_name }}"
        namespace: "{{ namespace }}"
      register: cluster_info
      failed_when: cluster_info.resources | length == 0

    - name: Check if target PVC exists
      kubernetes.core.k8s_info:
        api_version: v1
        kind: PersistentVolumeClaim
        name: "{{ target_pvc }}"
        namespace: "{{ namespace }}"
      register: pvc_info
      failed_when: pvc_info.resources | length == 0

    - name: Get cluster state
      ansible.builtin.set_fact:
        cluster_spec: "{{ cluster_info.resources[0].spec }}"
        cluster_status: "{{ cluster_info.resources[0].status }}"
        cluster_annotations: "{{ cluster_info.resources[0].metadata.annotations | default({}) }}"

    - name: Display cluster state
      ansible.builtin.debug:
        msg:
          - "Current instances: {{ cluster_spec.instances }}"
          - "Ready instances: {{ cluster_status.readyInstances | default(0) }}"
          - "Phase: {{ cluster_status.phase }}"
          - "Primary: {{ cluster_status.currentPrimary }}"
          - "PostgreSQL image: {{ cluster_spec.imageName }}"

    # --- Warn if cluster is degraded ---
    - name: Warn if cluster is not fully healthy
      ansible.builtin.debug:
        msg:
          - "WARNING: Cluster is not fully healthy ({{ cluster_status.readyInstances | default(0) }}/{{ cluster_spec.instances }})"
          - "Proceeding because primary health will be verified next."
      when: (cluster_status.readyInstances | default(0) | int) != (cluster_spec.instances | int)

    # --- Check for existing fences ---
    - name: Get existing fenced instances
      ansible.builtin.set_fact:
        existing_fence_raw: "{{ cluster_annotations['cnpg.io/fencedInstances'] | default('') }}"

    - name: Parse existing fence list
      ansible.builtin.set_fact:
        existing_fence_list: "{{ existing_fence_raw | from_json if existing_fence_raw | length > 0 else [] }}"

    - name: Warn about existing fences
      ansible.builtin.debug:
        msg:
          - "WARNING: Cluster already has fenced instances: {{ existing_fence_list }}"
          - "This playbook will add {{ target_pod }} to the fence list."
      when: existing_fence_list | length > 0

    # --- Safety checks ---
    - name: SAFETY CHECK - Verify target is not the primary
      ansible.builtin.fail:
        msg: "ABORT: {{ target_pod }} is the PRIMARY. Cannot heal primary. Failover first."
      when: target_pod == cluster_status.currentPrimary

    - name: SAFETY CHECK - Verify primary is healthy
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        name: "{{ cluster_status.currentPrimary }}"
        namespace: "{{ namespace }}"
      register: primary_pod_info

    - name: Check primary ready status
      ansible.builtin.fail:
        msg: "ABORT: Primary {{ cluster_status.currentPrimary }} is not healthy. Fix primary first."
      when: >
        primary_pod_info.resources | length == 0 or
        not (primary_pod_info.resources[0].status.containerStatuses[0].ready | default(false))

    - name: Get primary IP
      ansible.builtin.set_fact:
        primary_ip: "{{ primary_pod_info.resources[0].status.podIP }}"

    # --- Get postgres UID and GID separately ---
    - name: Get postgres UID from primary
      kubernetes.core.k8s_exec:
        namespace: "{{ namespace }}"
        pod: "{{ cluster_status.currentPrimary }}"
        container: postgres
        command: id -u postgres
      register: postgres_uid_result
      failed_when: false

    - name: Get postgres GID from primary
      kubernetes.core.k8s_exec:
        namespace: "{{ namespace }}"
        pod: "{{ cluster_status.currentPrimary }}"
        container: postgres
        command: id -g postgres
      register: postgres_gid_result
      failed_when: false

    - name: Set postgres UID/GID
      ansible.builtin.set_fact:
        postgres_uid: "{{ postgres_uid_result.stdout | default('26') | trim }}"
        postgres_gid: "{{ postgres_gid_result.stdout | default('26') | trim }}"

    - name: Display postgres UID/GID
      ansible.builtin.debug:
        msg: "Postgres UID/GID: {{ postgres_uid }}/{{ postgres_gid }}"

    # =========================================================================
    # Confirmation
    # =========================================================================
    - name: Display operation plan
      ansible.builtin.debug:
        msg:
          - "=== Plan ==="
          - "1. Fence instance {{ target_pod }} (CNPG stops managing it)"
          - "2. Create heal pod, then aggressively delete {{ target_pod }}"
          - "3. Clear pgdata on PVC {{ target_pvc }} (PVC preserved)"
          - "4. Run pg_basebackup from {{ cluster_status.currentPrimary }} ({{ primary_ip }})"
          - "5. Remove fence (CNPG takes over the replica)"

    - name: Pause for confirmation
      ansible.builtin.pause:
        prompt: "Type 'yes' to proceed"
      register: confirm
      when: not (auto_confirm | bool)

    - name: Verify confirmation
      ansible.builtin.fail:
        msg: "Operation cancelled by user"
      when:
        - not (auto_confirm | bool)
        - confirm.user_input != 'yes'

    # =========================================================================
    # Heal operation (block/rescue/always for cleanup)
    # =========================================================================
    - name: Heal operation
      block:
        # === STEP 1: Fence the instance (append to existing list) ===
        - name: STEP 1 - Build fence list with target pod
          ansible.builtin.set_fact:
            new_fence_list: "{{ (existing_fence_list + [target_pod]) | unique }}"

        - name: STEP 1 - Apply fence
          kubernetes.core.k8s:
            state: patched
            api_version: postgresql.cnpg.io/v1
            kind: Cluster
            name: "{{ cluster_name }}"
            namespace: "{{ namespace }}"
            definition:
              metadata:
                annotations:
                  cnpg.io/fencedInstances: "{{ new_fence_list | to_json }}"
          when: target_pod not in existing_fence_list

        - name: STEP 1 - Already fenced
          ansible.builtin.debug:
            msg: "Instance {{ target_pod }} already fenced."
          when: target_pod in existing_fence_list

        - name: Track fence state
          ansible.builtin.set_fact:
            heal_fence_applied: true

        - name: Wait for fence to take effect
          ansible.builtin.pause:
            seconds: 3

        # === STEP 2: Create heal pod FIRST (it will wait for PVC) ===
        - name: STEP 2 - Create heal pod
          kubernetes.core.k8s:
            state: present
            definition:
              apiVersion: v1
              kind: Pod
              metadata:
                name: "{{ heal_pod }}"
                namespace: "{{ namespace }}"
              spec:
                restartPolicy: Never
                securityContext:
                  runAsUser: "{{ postgres_uid | int }}"
                  runAsGroup: "{{ postgres_gid | int }}"
                  fsGroup: "{{ postgres_gid | int }}"
                containers:
                  - name: healer
                    image: "{{ cluster_spec.imageName }}"
                    command:
                      - sh
                      - -c
                      - |
                        set -e
                        echo "=== Step 1: Clearing pgdata ==="
                        if [ -f /var/lib/postgresql/data/pgdata/PG_VERSION ]; then
                          echo "WARNING: Found existing PG_VERSION file. Proceeding with clear..."
                        fi
                        rm -rf /var/lib/postgresql/data/pgdata/*
                        rm -rf /var/lib/postgresql/data/pgdata/.[!.]*
                        rm -rf /var/lib/postgresql/data/lost+found 2>/dev/null || true
                        echo "pgdata cleared."

                        echo "=== Step 2: Setting up TLS certificates ==="
                        mkdir -p /tmp/certs
                        cp /certs/ca/ca.crt /tmp/certs/
                        cp /certs/replication/tls.crt /tmp/certs/
                        cp /certs/replication/tls.key /tmp/certs/
                        chmod 600 /tmp/certs/tls.key
                        echo "TLS certs ready."

                        echo "=== Step 3: Running pg_basebackup ==="
                        pg_basebackup -h {{ primary_ip }} -p 5432 -U streaming_replica \
                          -D /var/lib/postgresql/data/pgdata \
                          -Fp -Xs -P -R \
                          --checkpoint=fast \
                          -d "sslmode=verify-ca sslcert=/tmp/certs/tls.crt sslkey=/tmp/certs/tls.key sslrootcert=/tmp/certs/ca.crt"

                        echo "=== pg_basebackup complete! ==="
                    volumeMounts:
                      - name: pgdata
                        mountPath: /var/lib/postgresql/data
                      - name: ca-certs
                        mountPath: /certs/ca
                        readOnly: true
                      - name: replication-certs
                        mountPath: /certs/replication
                        readOnly: true
                volumes:
                  - name: pgdata
                    persistentVolumeClaim:
                      claimName: "{{ target_pvc }}"
                  - name: ca-certs
                    secret:
                      secretName: "{{ ca_secret }}"
                      items:
                        - key: ca.crt
                          path: ca.crt
                  - name: replication-certs
                    secret:
                      secretName: "{{ replication_secret }}"
                      items:
                        - key: tls.crt
                          path: tls.crt
                        - key: tls.key
                          path: tls.key

        - name: Track heal pod state
          ansible.builtin.set_fact:
            heal_pod_created: true

        - name: Wait for heal pod to be registered
          ansible.builtin.pause:
            seconds: 2

        # === STEP 3: Aggressively delete target pod until heal pod gets PVC ===
        # Uses python kubernetes client (available in ansible-oci) for tight loop
        - name: STEP 3 - Aggressively delete target pod until heal pod acquires PVC
          ansible.builtin.shell: |
            python3 << 'PYEOF'
            import time, sys
            from kubernetes import client, config

            config.load_kube_config()
            v1 = client.CoreV1Api()

            ns = "{{ namespace }}"
            target = "{{ target_pod }}"
            healer = "{{ heal_pod }}"
            timeout = {{ delete_timeout }}

            elapsed = 0
            delete_count = 0
            while elapsed < timeout:
                try:
                    hp = v1.read_namespaced_pod_status(healer, ns)
                    phase = hp.status.phase
                except Exception:
                    phase = "Pending"

                if phase in ("Running", "Succeeded"):
                    print("HEAL_ACQUIRED delete_count=%d" % delete_count)
                    sys.exit(0)
                if phase == "Failed":
                    print("HEAL_FAILED")
                    sys.exit(1)

                try:
                    v1.delete_namespaced_pod(
                        target, ns,
                        grace_period_seconds=0,
                        propagation_policy="Background",
                    )
                    delete_count += 1
                    if delete_count % 10 == 0:
                        print("Deleted %d times, heal pod status: %s" % (delete_count, phase), file=sys.stderr)
                except client.exceptions.ApiException as e:
                    if e.status != 404:
                        print("Delete error: %s" % e.reason, file=sys.stderr)

                time.sleep(1)
                elapsed += 1

            print("TIMEOUT after %ds, heal pod never acquired PVC" % timeout)
            sys.exit(1)
            PYEOF
          args:
            executable: /bin/bash
          register: delete_loop_result
          changed_when: "'HEAL_ACQUIRED' in delete_loop_result.stdout"
          failed_when: delete_loop_result.rc != 0

        - name: Display PVC acquisition result
          ansible.builtin.debug:
            msg: "{{ delete_loop_result.stdout_lines | last }}"

        # === STEP 4: Wait for heal pod to complete pg_basebackup ===
        - name: STEP 4 - Wait for heal pod to complete
          kubernetes.core.k8s_info:
            api_version: v1
            kind: Pod
            name: "{{ heal_pod }}"
            namespace: "{{ namespace }}"
          register: heal_status
          until: >
            heal_status.resources | length > 0 and
            heal_status.resources[0].status.phase in ['Succeeded', 'Failed']
          retries: "{{ (heal_timeout / 10) | int }}"
          delay: 10

        - name: Fetch heal pod logs
          kubernetes.core.k8s_log:
            name: "{{ heal_pod }}"
            namespace: "{{ namespace }}"
          register: heal_logs
          failed_when: false

        - name: Show heal pod logs
          ansible.builtin.debug:
            msg: "{{ heal_logs.log_lines | default(['(no logs)']) }}"

        - name: Check if heal pod succeeded
          ansible.builtin.fail:
            msg: "Heal pod FAILED! See logs above."
          when: heal_status.resources[0].status.phase == 'Failed'

        # === Cleanup heal pod ===
        - name: Delete heal pod
          kubernetes.core.k8s:
            state: absent
            api_version: v1
            kind: Pod
            name: "{{ heal_pod }}"
            namespace: "{{ namespace }}"
            delete_options:
              gracePeriodSeconds: 0

        - name: Track heal pod cleaned
          ansible.builtin.set_fact:
            heal_pod_created: false

        - name: Wait for heal pod cleanup
          ansible.builtin.pause:
            seconds: 5

        # === STEP 5: Remove fence (only our target, preserve others) ===
        - name: STEP 5 - Build updated fence list without target
          ansible.builtin.set_fact:
            remaining_fence_list: "{{ new_fence_list | reject('eq', target_pod) | list }}"

        - name: STEP 5 - Remove fence annotation (target was only fenced instance)
          kubernetes.core.k8s:
            state: patched
            api_version: postgresql.cnpg.io/v1
            kind: Cluster
            name: "{{ cluster_name }}"
            namespace: "{{ namespace }}"
            definition:
              metadata:
                annotations:
                  cnpg.io/fencedInstances: null
          when: remaining_fence_list | length == 0

        - name: STEP 5 - Update fence list (other instances remain fenced)
          kubernetes.core.k8s:
            state: patched
            api_version: postgresql.cnpg.io/v1
            kind: Cluster
            name: "{{ cluster_name }}"
            namespace: "{{ namespace }}"
            definition:
              metadata:
                annotations:
                  cnpg.io/fencedInstances: "{{ remaining_fence_list | to_json }}"
          when: remaining_fence_list | length > 0

        - name: Track fence removed
          ansible.builtin.set_fact:
            heal_fence_applied: false

      # === RESCUE: Cleanup on failure ===
      rescue:
        - name: "RESCUE - Fetch heal pod logs (if pod exists)"
          kubernetes.core.k8s_log:
            name: "{{ heal_pod }}"
            namespace: "{{ namespace }}"
          register: rescue_logs
          failed_when: false
          when: heal_pod_created

        - name: "RESCUE - Display heal pod logs"
          ansible.builtin.debug:
            msg: "{{ rescue_logs.log_lines | default(['(no logs available)']) }}"
          when: heal_pod_created and rescue_logs.log is defined

        - name: "RESCUE - Delete heal pod"
          kubernetes.core.k8s:
            state: absent
            api_version: v1
            kind: Pod
            name: "{{ heal_pod }}"
            namespace: "{{ namespace }}"
            delete_options:
              gracePeriodSeconds: 0
          failed_when: false
          when: heal_pod_created

        - name: "RESCUE - Fence left in place"
          ansible.builtin.debug:
            msg:
              - "HEAL FAILED - fence left in place for safety."
              - "Instance {{ target_pod }} is still fenced."
              - ""
              - "To remove fence manually:"
              - "  kubectl annotate cluster {{ cluster_name }} -n {{ namespace }} cnpg.io/fencedInstances-"
              - ""
              - "Or to remove only {{ target_pod }} from fence list:"
              - "  kubectl get cluster {{ cluster_name }} -n {{ namespace }} -o jsonpath='{.metadata.annotations.cnpg\\.io/fencedInstances}'"
          when: heal_fence_applied

        - name: "RESCUE - Propagate failure"
          ansible.builtin.fail:
            msg: "Heal operation failed. Heal pod and fence have been cleaned up / reported above."

    # =========================================================================
    # Post-heal monitoring
    # =========================================================================
    # Force-delete the old pod so CNPG recreates it fresh (no CrashLoopBackOff
    # backoff from prior restarts). Without this, the pod can sit in backoff
    # for minutes before Kubernetes retries.
    - name: Delete target pod to clear CrashLoopBackOff history
      kubernetes.core.k8s:
        state: absent
        api_version: v1
        kind: Pod
        name: "{{ target_pod }}"
        namespace: "{{ namespace }}"
        delete_options:
          gracePeriodSeconds: 0
      failed_when: false

    - name: Wait for CNPG to recreate target pod
      ansible.builtin.pause:
        seconds: 5

    - name: Wait for target pod to come back online
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        name: "{{ target_pod }}"
        namespace: "{{ namespace }}"
      register: target_status
      until: >
        target_status.resources | length > 0 and
        target_status.resources[0].status.containerStatuses[0].ready | default(false)
      retries: 30
      delay: 10
      failed_when: false

    - name: Display final status
      kubernetes.core.k8s_info:
        api_version: postgresql.cnpg.io/v1
        kind: Cluster
        name: "{{ cluster_name }}"
        namespace: "{{ namespace }}"
      register: final_cluster

    - name: Display final cluster state
      ansible.builtin.debug:
        msg:
          - "=== Final Status ==="
          - "Cluster: {{ final_cluster.resources[0].status.phase }}"
          - "Ready: {{ final_cluster.resources[0].status.readyInstances | default(0) }}/{{ final_cluster.resources[0].spec.instances }}"

    - name: Get final pod list
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        namespace: "{{ namespace }}"
        label_selectors:
          - "cnpg.io/cluster={{ cluster_name }}"
      register: final_pods

    - name: Display pod status
      ansible.builtin.debug:
        msg: "{{ item.metadata.name }}: {{ item.status.phase }} ready={{ item.status.containerStatuses[0].ready | default(false) }}"
      loop: "{{ final_pods.resources }}"
      loop_control:
        label: "{{ item.metadata.name }}"

    - name: Operation complete
      ansible.builtin.debug:
        msg: "Replica {{ target_pod }} has been healed!"
