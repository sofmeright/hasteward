---
# cnpg-triage-cluster.yml - Read-only diagnostic triage for CNPG PostgreSQL clusters
#
# Collects cluster state, timeline analysis, replication status, WAL retention,
# and disk usage to produce a per-instance verdict and recommended action.
# Makes NO mutations - safe to run at any time.
#
# Usage:
#   docker run --rm \
#     -v ~/.kube:/root/.kube:ro \
#     -v /srv/dungeon/ansible:/app:ro \
#     prplanit/ansible-oci:2.20.1-v2 \
#     ansible-playbook k8s/recovery/cnpg-triage-cluster.yml \
#       -e cluster_name=zitadel-postgres \
#       -e namespace=zeldas-lullaby \
#       -e replica_number=3

- name: CNPG PostgreSQL Cluster Triage
  hosts: localhost
  connection: local
  gather_facts: true

  tasks:
    # =========================================================================
    # Validate inputs
    # =========================================================================
    - name: Validate required variables
      ansible.builtin.assert:
        that:
          - cluster_name is defined
          - namespace is defined
          - replica_number is defined
        fail_msg: "Required variables: cluster_name, namespace, replica_number"

    - name: Set derived variables
      ansible.builtin.set_fact:
        target_pod: "{{ cluster_name }}-{{ replica_number }}"

    - name: Display triage header
      ansible.builtin.debug:
        msg:
          - "=== CNPG Cluster Triage ==="
          - "Cluster: {{ cluster_name }}"
          - "Namespace: {{ namespace }}"
          - "Target replica: {{ target_pod }}"
          - "Timestamp: {{ ansible_date_time.iso8601 }}"

    # =========================================================================
    # 1. Cluster-level status
    # =========================================================================
    - name: Get CNPG Cluster CR
      kubernetes.core.k8s_info:
        api_version: postgresql.cnpg.io/v1
        kind: Cluster
        name: "{{ cluster_name }}"
        namespace: "{{ namespace }}"
      register: cluster_info
      failed_when: cluster_info.resources | length == 0

    - name: Set cluster facts
      ansible.builtin.set_fact:
        cluster_spec: "{{ cluster_info.resources[0].spec }}"
        cluster_status: "{{ cluster_info.resources[0].status }}"
        cluster_annotations: "{{ cluster_info.resources[0].metadata.annotations | default({}) }}"
        cluster_instances: "{{ cluster_info.resources[0].spec.instances }}"

    - name: Check for fenced instances
      ansible.builtin.set_fact:
        fenced_instances: "{{ cluster_annotations['cnpg.io/fencedInstances'] | default('[]') | from_json }}"

    - name: Display cluster status
      ansible.builtin.debug:
        msg:
          - "--- Cluster Status ---"
          - "Phase: {{ cluster_status.phase | default('Unknown') }}"
          - "Instances: {{ cluster_instances }}"
          - "Ready instances: {{ cluster_status.readyInstances | default(0) }}"
          - "Current primary: {{ cluster_status.currentPrimary | default('Unknown') }}"
          - "Target primary: {{ cluster_status.targetPrimary | default('Unknown') }}"
          - "Timeline ID: {{ cluster_status.timelineID | default('Unknown') }}"
          - "PostgreSQL image: {{ cluster_spec.imageName }}"
          - "Fenced instances: {{ fenced_instances }}"

    - name: Warn if target is fenced
      ansible.builtin.debug:
        msg: "WARNING: {{ target_pod }} is currently FENCED"
      when: target_pod in fenced_instances

    # =========================================================================
    # 2. Discover all pods for this cluster
    # =========================================================================
    - name: Get all cluster pods
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        namespace: "{{ namespace }}"
        label_selectors:
          - "cnpg.io/cluster={{ cluster_name }}"
      register: all_pods

    - name: Categorize pods
      ansible.builtin.set_fact:
        running_pods: "{{ all_pods.resources | selectattr('status.phase', 'eq', 'Running') | list }}"
        non_running_pods: "{{ all_pods.resources | rejectattr('status.phase', 'eq', 'Running') | list }}"

    - name: Display pod overview
      ansible.builtin.debug:
        msg:
          - "--- Pod Overview ---"
          - "Total pods: {{ all_pods.resources | length }}"
          - "Running: {{ running_pods | map(attribute='metadata.name') | list | join(', ') }}"
          - "Non-running: {{ non_running_pods | map(attribute='metadata.name') | list | join(', ') | default('none') }}"

    - name: Identify crash-looping pods (Running but not ready, high restarts)
      ansible.builtin.set_fact:
        crashloop_pods: >-
          {{ running_pods | selectattr('status.containerStatuses', 'defined')
             | selectattr('status.containerStatuses.0.ready', 'eq', false)
             | list }}

    - name: Display non-running pod details
      ansible.builtin.debug:
        msg: >-
          {{ item.metadata.name }}:
          phase={{ item.status.phase }}
          reason={{ item.status.containerStatuses[0].state.waiting.reason
            | default(item.status.containerStatuses[0].state.terminated.reason
            | default('N/A')) }}
          restarts={{ item.status.containerStatuses[0].restartCount | default(0) }}
      loop: "{{ non_running_pods }}"
      loop_control:
        label: "{{ item.metadata.name }}"
      when: non_running_pods | length > 0

    - name: Display crash-looping pod details
      ansible.builtin.debug:
        msg: "CRASH-LOOP: {{ item.metadata.name }}: phase=Running ready=false restarts={{ item.status.containerStatuses[0].restartCount | default(0) }}"
      loop: "{{ crashloop_pods }}"
      loop_control:
        label: "{{ item.metadata.name }}"
      when: crashloop_pods | length > 0

    # =========================================================================
    # 3. Timeline analysis - pg_controldata on each running instance
    # =========================================================================
    - name: Run pg_controldata on running instances
      kubernetes.core.k8s_exec:
        namespace: "{{ namespace }}"
        pod: "{{ item.metadata.name }}"
        container: postgres
        command: pg_controldata /var/lib/postgresql/data/pgdata
      loop: "{{ running_pods }}"
      loop_control:
        label: "{{ item.metadata.name }}"
      register: controldata_results
      failed_when: false

    - name: Parse pg_controldata for each instance
      ansible.builtin.set_fact:
        instance_controldata: >-
          {%- set result = [] -%}
          {%- for item in controldata_results.results -%}
            {%- set pod_name = item.item.metadata.name -%}
            {%- if item.rc is defined and item.rc == 0 -%}
              {%- set lines = item.stdout_lines | default([]) -%}
              {%- set state_line = lines | select('match', '^Database cluster state:') | first | default('') -%}
              {%- set timeline_line = lines | select('match', "^Latest checkpoint's TimeLineID:") | first | default('') -%}
              {%- set ckpt_loc_line = lines | select('match', '^Latest checkpoint location:') | first | default('') -%}
              {%- set ckpt_time_line = lines | select('match', "^Time of latest checkpoint:") | first | default('') -%}
              {%- set min_recovery_line = lines | select('match', '^Min recovery ending location:') | first | default('') -%}
              {%- set _ = result.append({
                'pod': pod_name,
                'reachable': true,
                'cluster_state': state_line.split(':',1)[1] | default('') | trim if ':' in state_line else 'unknown',
                'timeline': timeline_line.split(':',1)[1] | default('') | trim if ':' in timeline_line else 'unknown',
                'checkpoint_location': ckpt_loc_line.split(':',1)[1] | default('') | trim if ':' in ckpt_loc_line else 'unknown',
                'checkpoint_time': ckpt_time_line.split(':', 1)[1] | default('') | trim if ':' in ckpt_time_line else 'unknown',
                'min_recovery_end': min_recovery_line.split(':',1)[1] | default('') | trim if ':' in min_recovery_line else 'unknown'
              }) -%}
            {%- else -%}
              {%- set _ = result.append({
                'pod': pod_name,
                'reachable': true,
                'cluster_state': 'ERROR: pg_controldata failed',
                'timeline': 'unknown',
                'checkpoint_location': 'unknown',
                'checkpoint_time': 'unknown',
                'min_recovery_end': 'unknown',
                'error': item.stderr | default('unknown error')
              }) -%}
            {%- endif -%}
          {%- endfor -%}
          {{ result }}

    - name: Identify instances where pg_controldata exec failed
      ansible.builtin.set_fact:
        failed_controldata_pods: "{{ instance_controldata | selectattr('cluster_state', 'match', 'ERROR') | map(attribute='pod') | list }}"

    - name: Fetch logs from crash-looping instances for controldata fallback
      kubernetes.core.k8s_log:
        name: "{{ item }}"
        namespace: "{{ namespace }}"
        container: postgres
      loop: "{{ failed_controldata_pods }}"
      register: crashloop_logs
      failed_when: false
      when: failed_controldata_pods | length > 0

    - name: Parse controldata from CNPG instance manager logs
      ansible.builtin.set_fact:
        instance_controldata: >-
          {%- set updated = [] -%}
          {%- set log_data = {} -%}
          {%- set sentinel = '__NOT_FOUND__' -%}
          {%- if crashloop_logs.results is defined -%}
            {%- for log_result in crashloop_logs.results -%}
              {%- if log_result.log is defined -%}
                {%- set log_text = log_result.log -%}
                {%- set found_timeline = sentinel -%}
                {%- set found_state = sentinel -%}
                {%- set found_ckpt_loc = sentinel -%}
                {%- set found_ckpt_time = sentinel -%}
                {%- set found_min_recovery = sentinel -%}
                {%- if "TimeLineID:" in log_text -%}
                  {%- set chunk = log_text.split("TimeLineID:") -%}
                  {%- set last_tl = chunk[-1] -%}
                  {%- set found_timeline = last_tl.split('\\n')[0].split('"')[0] | trim -%}
                {%- endif -%}
                {%- if "Database cluster state:" in log_text -%}
                  {%- set chunk = log_text.split("Database cluster state:") -%}
                  {%- set last_st = chunk[-1] -%}
                  {%- set found_state = last_st.split('\\n')[0].split('"')[0] | trim -%}
                {%- endif -%}
                {%- if "Latest checkpoint location:" in log_text -%}
                  {%- set chunk = log_text.split("Latest checkpoint location:") -%}
                  {%- set last_loc = chunk[-1] -%}
                  {%- set found_ckpt_loc = last_loc.split('\\n')[0].split('"')[0] | trim -%}
                {%- endif -%}
                {%- if "Time of latest checkpoint:" in log_text -%}
                  {%- set chunk = log_text.split("Time of latest checkpoint:") -%}
                  {%- set last_time = chunk[-1] -%}
                  {%- set found_ckpt_time = last_time.split('\\n')[0].split('"')[0] | trim -%}
                {%- endif -%}
                {%- if "Min recovery ending loc" in log_text and "timeline:" in log_text -%}
                  {%- set chunk = log_text.split("timeline:") -%}
                  {%- set last_min = chunk[-1] -%}
                  {%- set found_min_recovery = last_min.split('\\n')[0].split('"')[0] | trim -%}
                {%- endif -%}
                {%- set _ = log_data.update({log_result.item: {
                  'timeline': found_timeline if found_timeline != sentinel else 'unknown',
                  'cluster_state': found_state if found_state != sentinel else 'unknown',
                  'checkpoint_location': found_ckpt_loc if found_ckpt_loc != sentinel else 'unknown',
                  'checkpoint_time': found_ckpt_time if found_ckpt_time != sentinel else 'unknown',
                  'min_recovery_end': found_min_recovery if found_min_recovery != sentinel else 'unknown'
                }}) -%}
              {%- endif -%}
            {%- endfor -%}
          {%- endif -%}
          {%- for inst in instance_controldata -%}
            {%- if inst.pod in log_data and log_data[inst.pod].timeline != 'unknown' -%}
              {%- set ld = log_data[inst.pod] -%}
              {%- set _ = updated.append({
                'pod': inst.pod,
                'reachable': false,
                'source': 'logs',
                'cluster_state': ld.cluster_state,
                'timeline': ld.timeline,
                'checkpoint_location': ld.checkpoint_location,
                'checkpoint_time': ld.checkpoint_time,
                'min_recovery_end': ld.min_recovery_end
              }) -%}
            {%- else -%}
              {%- set _ = updated.append(inst) -%}
            {%- endif -%}
          {%- endfor -%}
          {{ updated }}

    - name: Display timeline analysis
      ansible.builtin.debug:
        msg:
          - "--- Timeline Analysis ---"

    - name: Display per-instance controldata
      ansible.builtin.debug:
        msg:
          - "{{ item.pod }}:{{ ' (from pod logs - exec failed)' if item.source | default('exec') == 'logs' else '' }}"
          - "  State: {{ item.cluster_state }}"
          - "  Timeline: {{ item.timeline }}"
          - "  Checkpoint LSN: {{ item.checkpoint_location }}"
          - "  Checkpoint time: {{ item.checkpoint_time }}"
          - "  Min recovery end: {{ item.min_recovery_end }}"
      loop: "{{ instance_controldata }}"
      loop_control:
        label: "{{ item.pod }}"

    - name: Identify primary timeline
      ansible.builtin.set_fact:
        primary_timeline: "{{ (instance_controldata | selectattr('pod', 'eq', cluster_status.currentPrimary | default('')) | first | default({})).timeline | default('unknown') }}"

    - name: Flag timeline divergence
      ansible.builtin.debug:
        msg: "DIVERGENCE: {{ item.pod }} is on timeline {{ item.timeline }} but primary is on timeline {{ primary_timeline }}"
      loop: "{{ instance_controldata }}"
      loop_control:
        label: "{{ item.pod }}"
      when:
        - primary_timeline != 'unknown'
        - item.timeline != 'unknown'
        - item.timeline != primary_timeline
        - item.pod != cluster_status.currentPrimary | default('')

    # =========================================================================
    # 4. Replication status from primary
    # =========================================================================
    - name: Check if primary is running
      ansible.builtin.set_fact:
        primary_is_running: "{{ cluster_status.currentPrimary | default('') in (running_pods | map(attribute='metadata.name') | list) }}"

    - name: Get replication status from primary
      kubernetes.core.k8s_exec:
        namespace: "{{ namespace }}"
        pod: "{{ cluster_status.currentPrimary }}"
        container: postgres
        command: >
          psql -U postgres -d postgres -t -A -F '|' -c
          "SELECT client_addr, state, sent_lsn, write_lsn, flush_lsn, replay_lsn,
                  write_lag, flush_lag, replay_lag, application_name
           FROM pg_stat_replication ORDER BY application_name"
      register: replication_status
      failed_when: false
      when: primary_is_running

    - name: Display replication status header
      ansible.builtin.debug:
        msg:
          - "--- Replication Status (from {{ cluster_status.currentPrimary | default('N/A') }}) ---"

    - name: Display replication status
      ansible.builtin.debug:
        msg: "{{ item }}"
      loop: "{{ replication_status.stdout_lines | default([]) }}"
      when:
        - primary_is_running
        - replication_status.rc | default(1) == 0
        - replication_status.stdout_lines | default([]) | length > 0

    - name: Display no replication warning
      ansible.builtin.debug:
        msg: "WARNING: No active replication connections found"
      when:
        - primary_is_running
        - replication_status.rc | default(1) == 0
        - replication_status.stdout_lines | default([]) | length == 0

    - name: Display primary unreachable warning
      ansible.builtin.debug:
        msg: "WARNING: Primary is not running - cannot query replication status"
      when: not primary_is_running

    # =========================================================================
    # 5. WAL retention / replication slots from primary
    # =========================================================================
    - name: Get replication slots from primary
      kubernetes.core.k8s_exec:
        namespace: "{{ namespace }}"
        pod: "{{ cluster_status.currentPrimary }}"
        container: postgres
        command: >
          psql -U postgres -d postgres -t -A -F '|' -c
          "SELECT slot_name, slot_type, active, restart_lsn,
                  confirmed_flush_lsn,
                  pg_wal_lsn_diff(pg_current_wal_lsn(), restart_lsn) AS bytes_behind
           FROM pg_replication_slots ORDER BY slot_name"
      register: slot_status
      failed_when: false
      when: primary_is_running

    - name: Display replication slots header
      ansible.builtin.debug:
        msg:
          - "--- Replication Slots ---"

    - name: Display replication slots
      ansible.builtin.debug:
        msg: "{{ item }}"
      loop: "{{ slot_status.stdout_lines | default([]) }}"
      when:
        - primary_is_running
        - slot_status.rc | default(1) == 0
        - slot_status.stdout_lines | default([]) | length > 0

    - name: Display no slots info
      ansible.builtin.debug:
        msg: "No replication slots found"
      when:
        - primary_is_running
        - slot_status.rc | default(1) == 0
        - slot_status.stdout_lines | default([]) | length == 0

    - name: Get current WAL position and max_slot_wal_keep_size from primary
      kubernetes.core.k8s_exec:
        namespace: "{{ namespace }}"
        pod: "{{ cluster_status.currentPrimary }}"
        container: postgres
        command: >
          psql -U postgres -d postgres -t -A -F '|' -c
          "SELECT pg_current_wal_lsn() AS current_lsn,
                  current_setting('max_slot_wal_keep_size') AS max_slot_wal_keep_size,
                  current_setting('wal_keep_size') AS wal_keep_size"
      register: wal_info
      failed_when: false
      when: primary_is_running

    - name: Display WAL info
      ansible.builtin.debug:
        msg:
          - "--- WAL Info ---"
          - "{{ wal_info.stdout | default('Primary unreachable') }}"
      when: primary_is_running

    # =========================================================================
    # 6. Disk space on each running instance
    # =========================================================================
    - name: Check disk space on running instances
      kubernetes.core.k8s_exec:
        namespace: "{{ namespace }}"
        pod: "{{ item.metadata.name }}"
        container: postgres
        command: df -h /var/lib/postgresql/data
      loop: "{{ running_pods }}"
      loop_control:
        label: "{{ item.metadata.name }}"
      register: disk_results
      failed_when: false

    - name: Display disk space header
      ansible.builtin.debug:
        msg:
          - "--- Disk Space ---"

    - name: Display disk usage per instance
      ansible.builtin.debug:
        msg:
          - "{{ item.item.metadata.name }}:"
          - "{{ item.stdout_lines | default(['  unable to check']) | join('\n') }}"
      loop: "{{ disk_results.results }}"
      loop_control:
        label: "{{ item.item.metadata.name }}"

    # =========================================================================
    # 7. Target replica specific checks
    # =========================================================================
    - name: Check target pod status
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        name: "{{ target_pod }}"
        namespace: "{{ namespace }}"
      register: target_pod_info

    - name: Set target pod facts
      vars:
        _has_pod: "{{ target_pod_info.resources | length > 0 }}"
        _has_cs: >-
          {{ _has_pod and
             (target_pod_info.resources[0].status.containerStatuses
              | default([]) | length > 0) }}
      ansible.builtin.set_fact:
        target_exists: "{{ _has_pod }}"
        target_phase: >-
          {{ target_pod_info.resources[0].status.phase | default('N/A')
             if _has_pod else 'NOT FOUND' }}
        target_restarts: >-
          {{ target_pod_info.resources[0].status.containerStatuses[0].restartCount
             | default(0) if _has_cs else 'N/A' }}
        target_ready: >-
          {{ target_pod_info.resources[0].status.containerStatuses[0].ready
             | default(false) if _has_cs else false }}

    - name: Get target controldata
      ansible.builtin.set_fact:
        target_controldata: "{{ instance_controldata | selectattr('pod', 'eq', target_pod) | first | default({}) }}"

    - name: Set target timeline
      ansible.builtin.set_fact:
        target_timeline: "{{ target_controldata.timeline | default('unknown') }}"

    # =========================================================================
    # 8. Summary verdict
    # =========================================================================
    - name: Build per-instance verdicts
      ansible.builtin.set_fact:
        instance_verdicts: >-
          {%- set result = [] -%}
          {%- set primary_name = cluster_status.currentPrimary | default('') -%}
          {%- for inst in instance_controldata -%}
            {%- set verdict = 'HEALTHY' -%}
            {%- set reasons = [] -%}
            {%- if not inst.reachable | default(true) -%}
              {%- set _ = reasons.append('crash-looping (data from pod logs)') -%}
            {%- endif -%}
            {%- if inst.timeline != 'unknown' and primary_timeline != 'unknown' and inst.timeline != primary_timeline and inst.pod != primary_name -%}
              {%- set verdict = 'DIVERGED' -%}
              {%- set _ = reasons.append('timeline ' + inst.timeline + ' != primary timeline ' + primary_timeline) -%}
            {%- elif inst.cluster_state is defined and 'ERROR' in inst.cluster_state -%}
              {%- set verdict = 'UNREACHABLE' -%}
              {%- set _ = reasons.append('pg_controldata failed and no data in logs') -%}
            {%- elif not inst.reachable | default(true) and inst.timeline == primary_timeline -%}
              {%- set verdict = 'CRASH_LOOP' -%}
              {%- set _ = reasons.append('same timeline but crash-looping') -%}
            {%- endif -%}
            {%- set _ = result.append({
              'pod': inst.pod,
              'verdict': verdict,
              'timeline': inst.timeline,
              'reasons': reasons
            }) -%}
          {%- endfor -%}
          {%- for pod in non_running_pods -%}
            {%- set _ = result.append({
              'pod': pod.metadata.name,
              'verdict': 'UNREACHABLE',
              'timeline': 'unknown',
              'reasons': ['pod not running (phase: ' + pod.status.phase + ')']
            }) -%}
          {%- endfor -%}
          {{ result }}

    - name: Check disk space verdicts
      ansible.builtin.set_fact:
        disk_verdicts: >-
          {%- set result = [] -%}
          {%- for item in disk_results.results -%}
            {%- set pod_name = item.item.metadata.name -%}
            {%- if item.rc | default(1) == 0 and item.stdout_lines | default([]) | length > 1 -%}
              {%- set df_line = item.stdout_lines[-1] -%}
              {%- set parts = df_line.split() -%}
              {%- if parts | length >= 5 -%}
                {%- set use_pct = parts[4] | replace('%','') | int(default=0) -%}
                {%- if use_pct >= 90 -%}
                  {%- set _ = result.append({'pod': pod_name, 'verdict': 'LOW_DISK', 'usage': parts[4]}) -%}
                {%- endif -%}
              {%- endif -%}
            {%- endif -%}
          {%- endfor -%}
          {{ result }}

    - name: Merge disk verdicts into instance verdicts
      ansible.builtin.set_fact:
        instance_verdicts: >-
          {%- set low_disk_pods = disk_verdicts | map(attribute='pod') | list -%}
          {%- set result = [] -%}
          {%- for v in instance_verdicts -%}
            {%- if v.pod in low_disk_pods -%}
              {%- set disk_info = disk_verdicts | selectattr('pod', 'eq', v.pod) | first -%}
              {%- set new_reasons = v.reasons + ['disk usage: ' + disk_info.usage] -%}
              {%- set new_verdict = 'LOW_DISK' if v.verdict == 'HEALTHY' else v.verdict -%}
              {%- set _ = result.append({'pod': v.pod, 'verdict': new_verdict, 'timeline': v.timeline, 'reasons': new_reasons}) -%}
            {%- else -%}
              {%- set _ = result.append(v) -%}
            {%- endif -%}
          {%- endfor -%}
          {{ result }}

    - name: Determine target replica verdict
      ansible.builtin.set_fact:
        target_verdict: "{{ instance_verdicts | selectattr('pod', 'eq', target_pod) | first | default({'verdict': 'UNREACHABLE', 'reasons': ['pod not found in analysis']}) }}"
        target_can_catch_up: >-
          {%- if target_timeline == 'unknown' or primary_timeline == 'unknown' -%}
            false
          {%- elif target_timeline == primary_timeline -%}
            true
          {%- else -%}
            false
          {%- endif -%}

    - name: Display summary
      ansible.builtin.debug:
        msg:
          - ""
          - "============================================================"
          - "  TRIAGE SUMMARY"
          - "============================================================"
          - ""
          - "Cluster: {{ cluster_name }} ({{ namespace }})"
          - "Primary: {{ cluster_status.currentPrimary | default('Unknown') }} (timeline {{ primary_timeline }})"
          - "Phase: {{ cluster_status.phase | default('Unknown') }}"
          - "Ready: {{ cluster_status.readyInstances | default(0) }}/{{ cluster_instances }}"
          - ""

    - name: Display per-instance verdicts
      ansible.builtin.debug:
        msg: "  {{ item.verdict | upper }}: {{ item.pod }} (timeline {{ item.timeline }}){{ ' - ' + item.reasons | join(', ') if item.reasons | length > 0 else '' }}"
      loop: "{{ instance_verdicts }}"
      loop_control:
        label: "{{ item.pod }}"

    - name: Display target replica assessment
      ansible.builtin.debug:
        msg:
          - ""
          - "--- Target Replica: {{ target_pod }} ---"
          - "Verdict: {{ target_verdict.verdict }}"
          - "Pod phase: {{ target_phase }}"
          - "Restarts: {{ target_restarts }}"
          - "Ready: {{ target_ready }}"
          - "Timeline: {{ target_timeline }} (primary: {{ primary_timeline }})"
          - "Can catch up via streaming: {{ target_can_catch_up | trim }}"

    - name: Display recommendation - needs heal
      ansible.builtin.debug:
        msg:
          - ""
          - "--- RECOMMENDATION ---"
          - "{{ target_pod }} is DIVERGED (timeline {{ target_timeline }} vs primary {{ primary_timeline }})"
          - "The replica cannot catch up via streaming replication."
          - "Action: Run cnpg-heal-replica to re-basebackup from primary."
          - ""
          - "  docker run --rm \\"
          - "    -v ~/.kube:/root/.kube:ro \\"
          - "    -v /srv/dungeon/ansible:/app:ro \\"
          - "    prplanit/ansible-oci:2.20.1-v2 \\"
          - "    ansible-playbook k8s/recovery/cnpg-heal-replica.yml \\"
          - "      -e cluster_name={{ cluster_name }} \\"
          - "      -e namespace={{ namespace }} \\"
          - "      -e replica_number={{ replica_number }}"
      when: target_verdict.verdict == 'DIVERGED' or (target_timeline != primary_timeline and target_timeline != 'unknown' and primary_timeline != 'unknown')

    - name: Display recommendation - healthy
      ansible.builtin.debug:
        msg:
          - ""
          - "--- RECOMMENDATION ---"
          - "{{ target_pod }} appears HEALTHY and on the same timeline as primary."
          - "If the pod is crash-looping, check pod events and logs for other issues."
      when:
        - target_verdict.verdict == 'HEALTHY'
        - target_can_catch_up | trim | bool

    - name: Display recommendation - unreachable
      ansible.builtin.debug:
        msg:
          - ""
          - "--- RECOMMENDATION ---"
          - "{{ target_pod }} is UNREACHABLE (not running)."
          - "Cannot determine timeline status. Check pod events:"
          - "  kubectl describe pod {{ target_pod }} -n {{ namespace }}"
          - "  kubectl logs {{ target_pod }} -n {{ namespace }} --previous"
          - ""
          - "If the pod keeps crash-looping without starting PostgreSQL,"
          - "it likely needs a heal (pg_basebackup from primary)."
      when:
        - target_verdict.verdict == 'UNREACHABLE'

    - name: Display recommendation - crash loop same timeline
      ansible.builtin.debug:
        msg:
          - ""
          - "--- RECOMMENDATION ---"
          - "{{ target_pod }} is crash-looping but on the SAME timeline ({{ target_timeline }}) as primary."
          - "This is unusual - the replica data may be consistent but something else is wrong."
          - "Check pod events and logs:"
          - "  kubectl describe pod {{ target_pod }} -n {{ namespace }}"
          - "  kubectl logs {{ target_pod }} -n {{ namespace }} --tail=100"
          - ""
          - "If logs show WAL-related errors, a heal may still be needed."
      when: target_verdict.verdict == 'CRASH_LOOP'

    - name: Display recommendation - low disk
      ansible.builtin.debug:
        msg:
          - ""
          - "--- RECOMMENDATION ---"
          - "{{ target_pod }} has LOW DISK space."
          - "Free up space or expand the PVC before attempting recovery."
      when: target_verdict.verdict == 'LOW_DISK'

    - name: Triage complete
      ansible.builtin.debug:
        msg: "=== Triage complete ==="
